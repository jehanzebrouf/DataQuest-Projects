{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hacker News' Posts Analysis\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "We are here to analyse these posts to answer the following questions: \n",
    "\n",
    "Do Ask HN or Show HN receive more comments on average?\n",
    "\n",
    "Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "hn = list(reader(open('hacker_news.csv'))) #reading the csv file\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0] #making a list of the header row\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "hn = hn[1:] #removing the header from the dataset list hn and checking the same\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ask_posts, show_posts, other_posts = [],[],[] #making lists of ask hn, show hn, and other posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#populating above mentioned list\n",
    "\n",
    "for row in hn: \n",
    "    title = row[1]\n",
    "    cc_title = title.lower()\n",
    "    if cc_title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif cc_title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744 1162 17194\n"
     ]
    }
   ],
   "source": [
    "print(len(ask_posts), len(show_posts), len(other_posts)) #checking the length of these posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20'], ['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the average no. of comments for ask_posts, show_posts, and comparing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The average no of comments for an ASK HN post is 14.038417431192661\n",
      " The average no of comments for an SHOW HN post is 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_ask_comments = 0       #checking total comments in ask_posts\n",
    "\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])  #adding number of comments of row to total.\n",
    "\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "\n",
    "#Doing the Same for show_posts below\n",
    "\n",
    "total_show_comments = 0       #checking total comments in show_posts\n",
    "\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])  #adding number of comments of row to total.\n",
    "\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "\n",
    "print(' The average no of comments for an ASK HN post is', avg_ask_comments)\n",
    "print(' The average no of comments for an SHOW HN post is', avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We find from the above analysis that on average, ASK HN posts receive more comments than SHOW HN posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we'll determine if ask posts created at a certain TIME are more likely to attract comments. \n",
    "\n",
    "#### We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making a list which contains information of time of creation and num of comments\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts: \n",
    "    to_app = [row[6], int(row[4])]\n",
    "    result_list.append(to_app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_by_hour, comments_by_hour = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14': 107, '15': 116, '05': 46, '06': 44, '17': 100, '22': 71, '23': 68, '09': 45, '10': 59, '08': 48, '20': 80, '03': 54, '16': 108, '07': 34, '13': 85, '04': 47, '01': 60, '00': 55, '19': 110, '18': 109, '02': 58, '21': 109, '12': 73, '11': 58}\n"
     ]
    }
   ],
   "source": [
    "# Making Two Dictionaries\n",
    "#counts_by_hour: contains the number of ask posts created during each hour of the day.\n",
    "#comments_by_hour: contains the corresponding number of comments ask posts created at each hour received.\n",
    "\n",
    "for row in result_list:\n",
    "    created_at_time = dt.datetime.strptime(row[0], \"%m/%d/%Y %H:%M\").time()\n",
    "    created_at_hour = created_at_time.strftime(\"%H\")\n",
    "    \n",
    "    if created_at_hour not in counts_by_hour:\n",
    "        counts_by_hour[created_at_hour] = 1\n",
    "        comments_by_hour[created_at_hour] = row[1]\n",
    "    else: \n",
    "        counts_by_hour[created_at_hour] += 1\n",
    "        comments_by_hour[created_at_hour] += row[1]\n",
    "    \n",
    "print(counts_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14': 1416, '15': 4477, '05': 464, '06': 397, '17': 1146, '22': 479, '23': 543, '09': 251, '10': 793, '08': 492, '20': 1722, '03': 421, '16': 1814, '07': 267, '13': 1253, '04': 337, '01': 683, '00': 447, '19': 1188, '18': 1439, '02': 1381, '21': 1745, '12': 687, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#making a list of average number of comments per post for posts created during each hour of the day.\n",
    "\n",
    "acbh = [] #average comments per post by hour.\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    av = comments_by_hour[hour]/counts_by_hour[hour]\n",
    "    acbh.append([hour, av])\n",
    "\n",
    "avg_by_hour = acbh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['14', 13.233644859813085], ['15', 38.5948275862069], ['05', 10.08695652173913], ['06', 9.022727272727273], ['17', 11.46], ['22', 6.746478873239437], ['23', 7.985294117647059], ['09', 5.5777777777777775], ['10', 13.440677966101696], ['08', 10.25], ['20', 21.525], ['03', 7.796296296296297], ['16', 16.796296296296298], ['07', 7.852941176470588], ['13', 14.741176470588234], ['04', 7.170212765957447], ['01', 11.383333333333333], ['00', 8.127272727272727], ['19', 10.8], ['18', 13.20183486238532], ['02', 23.810344827586206], ['21', 16.009174311926607], ['12', 9.41095890410959], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Now we will be sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.233644859813085, '14'], [38.5948275862069, '15'], [10.08695652173913, '05'], [9.022727272727273, '06'], [11.46, '17'], [6.746478873239437, '22'], [7.985294117647059, '23'], [5.5777777777777775, '09'], [13.440677966101696, '10'], [10.25, '08'], [21.525, '20'], [7.796296296296297, '03'], [16.796296296296298, '16'], [7.852941176470588, '07'], [14.741176470588234, '13'], [7.170212765957447, '04'], [11.383333333333333, '01'], [8.127272727272727, '00'], [10.8, '19'], [13.20183486238532, '18'], [23.810344827586206, '02'], [16.009174311926607, '21'], [9.41095890410959, '12'], [11.051724137931034, '11']]\n"
     ]
    }
   ],
   "source": [
    "#Creating a list that equals avg_by_hour but with swapped columns.\n",
    "\n",
    "swap_avg_by_hour=[]\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.5948275862069, '15']\n",
      "[23.810344827586206, '02']\n",
      "[21.525, '20']\n",
      "[16.796296296296298, '16']\n",
      "[16.009174311926607, '21']\n",
      "[14.741176470588234, '13']\n",
      "[13.440677966101696, '10']\n",
      "[13.233644859813085, '14']\n",
      "[13.20183486238532, '18']\n",
      "[11.46, '17']\n",
      "[11.383333333333333, '01']\n",
      "[11.051724137931034, '11']\n",
      "[10.8, '19']\n",
      "[10.25, '08']\n",
      "[10.08695652173913, '05']\n",
      "[9.41095890410959, '12']\n",
      "[9.022727272727273, '06']\n",
      "[8.127272727272727, '00']\n",
      "[7.985294117647059, '23']\n",
      "[7.852941176470588, '07']\n",
      "[7.796296296296297, '03']\n",
      "[7.170212765957447, '04']\n",
      "[6.746478873239437, '22']\n",
      "[5.5777777777777775, '09']\n"
     ]
    }
   ],
   "source": [
    "#Sorting the above list in descending order.\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "for element in sorted_swap: print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments:  \n",
      "\n",
      " 15:00: 38.5948275862069 average comments per post.\n",
      " 02:00: 23.810344827586206 average comments per post.\n",
      " 20:00: 21.525 average comments per post.\n",
      " 16:00: 16.796296296296298 average comments per post.\n",
      " 21:00: 16.009174311926607 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Posts Comments: ', '\\n')\n",
    "for element in sorted_swap[:5]:\n",
    "    print(' {}:00: {} average comments per post.' .format(element[1], element[0]), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlusions \n",
    "\n",
    "Based on our findings above, the optimum time to make an ASK HN post for receiving maximum number of comments would be 3pm-4pm, 8pm-9pm, and at 2am."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
